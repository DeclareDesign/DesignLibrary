---
title: "Cluster Sampling"
output: rmarkdown::html_vignette
bibliography: bib.bib
nocite: | 
  @murray1998design  
vignette: >
  %\VignetteIndexEntry{Cluster Sampling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r MIDA, echo = FALSE,include = FALSE}
library(DesignLibrary)
library(ggplot2)
library(knitr)
```

Researchers often cannot randomly sample at the individual level because it may, among other reasons, be too costly or logistically impractical. Instead, they may choose to randomly sample households, political precincts, or any group of individuals in order to draw inferences about the population. This strategy may be cheaper and simpler but may also introduce risks of less precise estimates.

<!-- Include reference to simple random sampling vignette below -->
<!-- In *Simple Random Sampling*, we discused the example of estimating the average political ideology in Portola, California. Consider instead  -->

Say we are interested in the average party ideology in the entire state of California. Using cluster sampling, we randomly sample counties within the state, and within each selected county, randomly sample individuals to survey.

Assuming enough variation in the outcome of interest, the random assignment of equal-sized clusters yields unbiased but imprecise estimates. By sampling clusters, we select groups of individuals who may share common attributes. Unlike simple random sampling, we need to take  account of this intra-cluster correlation in our estimation of the standard error.^[The intra-cluster correlation coefficient (ICC) can be calculated directly and is a feature of this design.] The higher the degree of within-cluster similarity, the more variance we observe in cluster-level averages and the more imprecise are our estimates.^[In ordinary least square (OLS) models, we assume errors are independent (error terms between individual observations are uncorrelated with each other) and homoskedastic (the size of errors is homogeneous across individuals). In reality, this is often not the case with cluster sampling.] We address this by considering cluster-robust standard errors in our answer strategy below.

## Design Declaration

- **M**odel: 

    We specify the variable of interest $Y$ (political ideology, say) as a discrete variable ranging from 1 (most liberal) to 7 (most conservative). We do not define a functional model since we are interested in the population mean of $Y$. The model also includes information about the number of sampled clusters and the number of individuals per cluster.

- **I**nquiry: 

    Our estimand is the population mean of political identification $Y$. Because we employed random sampling, we can expect the value of the sample mean ($\widehat{\overline{y}}$) to approximate the true population parameter ($\widehat{\overline{Y}}$).

- **D**ata strategy: 

    Sampling follows a two-stage strategy. We first draw a random sample 30 counties in California, and in each county select 20 individuals at random. This guarantees that each county has the same probability of being included in the sample and each resident within a county the same probability of being in the sample. In this design we estimate $Y$ for n = 600 respondents.

- **A**nswer strategy: 

    We estimate the population mean with the sample mean estimator: $\widehat{\overline{Y}} = \frac{1}{n} \sum_1^n Y_i$, and estimate standard errors under the assumption of independent and heteroskedastic errors as well as cluster-robust standard errors to take into account correlation of errors within clusters. Below we demonstrate the the imprecision of our estimated $\widehat{\overline{Y}}$ when we cluster standard errors and when we do not in the presence of an intracluster correlation coefficient (ICC) of 0.402.


```{r,eval = TRUE, code = get_design_code(cluster_sampling_designer(n_clusters = 30, n_i_in_cluster = 20, icc = 0.402))}
```

## Takeaways

```{r}
diagnosis <- diagnose_design(cluster_sampling_design, sims = 25)
```

```{r,eval = TRUE, echo = FALSE}
kable(reshape_diagnosis(diagnosis)[, -c(1:2, 4:6)], digits = 2)
```

To appreciate the role of clustering better we also plot simulated values of our estimand with standard errors not clustered and with clustered standard errors. To do this we first add an additional estimator to the design that does not take account of clusters. 

```{r plot setup, echo=TRUE, warning=FALSE}
new_design <- cluster_sampling_design + declare_estimator(Y ~ 1,
                                        method = lm_robust,
                                        inquiry = estimand,
                                        label = "Naive Standard Errors")
diagnosis <- diagnose_design(new_design, sims = 25)
```

```{r plot, echo=FALSE, warning=FALSE}


sims <- diagnosis$simulations

dd_theme <-
  function() {
    theme_bw() +
      theme(
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        panel.border = element_blank(),
        panel.grid.major = element_line(color = '#eeeeee'),
        strip.background = element_blank(),
        legend.position = "bottom"
        # text = element_text(family = "Palatino")
        )
  }

  sims$covered <- factor(1 + (sims$conf.low < sims$estimand & sims$estimand < sims$conf.high), 1:2, labels = c("Estimand not covered by confidence interval", "Estimand covered by confidence interval"))
  sims$estimator <- as.factor(sims$estimator)
  sims$estimator <- factor(sims$estimator, levels = rev(levels(sims$estimator)))
  sims$inquiry  <- as.factor(sims$inquiry)
  
  ggplot(sims, aes(x=estimate)) +
    geom_errorbar(aes(ymin=conf.low, ymax=conf.high, color=covered), alpha=.4) +
    geom_hline(aes(yintercept=mean(estimand))) +
    geom_text(aes(x=x, y=y, label=label),
              data=function(df){
                data.frame(x=min(df$estimate),
                           y=mean(df$estimand),
                           label=sprintf('  Avg Estimand:\n  %4.3f', mean(df$estimand)),
                           stringsAsFactors = FALSE)
              }, hjust='left') +
    facet_wrap(inquiry~estimator) +
    ylab("Estimate") +
    scale_x_continuous(labels=NULL, breaks = NULL, name='') +
    scale_color_discrete(drop=FALSE, name = '') +
    coord_flip() +
    dd_theme()
  
```

The figure above may give us the impression that our estimate with clustered standard errors is less precise, when in fact, it correctly accounts for the uncertainty surrounding our estimates. The blue lines in the graph demonstrate the estimates from simulations which contain our estimand. As our table and graphs show, the share of these simulations over the total number of simulations, also known as coverage, is (correctly) close to 95% in estimations with clustered standard errors and 54% in estimations without clustered standard errors. As expected, the mean estimate itself and the bias is the same in both specifications.

## References